# üßæ Introducci√≥n
En las empresas de las telecomunicaciones, retener clientes es tan importante como adquirir nuevos. El abandono de clientes (churn) representa una p√©rdida significativa de ingresos para las empresas del sector. Comprender los factores que influyen en la decisi√≥n de un cliente de cancelar un servicio se vuelve clave para anticipar comportamientos futuros y tomar acciones preventivas.

Gracias al crecimiento del an√°lisis de datos y la inteligencia artificial, hoy es posible aplicar modelos de machine learning que permiten detectar patrones de comportamiento y predecir qu√© clientes tienen mayor riesgo de abandonar el servicio. Esta capacidad predictiva no solo optimiza campa√±as de fidelizaci√≥n, sino que tambi√©n mejora la experiencia general del cliente y la eficiencia operativa de la empresa.

# üéØ Objetivo del Proyecto
Este proyecto tiene como objetivo predecir si un cliente abandonar√° el servicio bas√°ndose en su comportamiento y caracter√≠sticas contractuales, utilizando t√©cnicas de ciencia de datos y aprendizaje autom√°tico.

Para ello, se emplear√° el dataset p√∫blico [Telco Customer Churn de Kaggle](https://www.kaggle.com/datasets/blastchar/telco-customer-churn), que incluye informaci√≥n detallada sobre miles de clientes de una empresa de telecomunicaciones, como:
G√©nero
Tiempo como cliente
Servicios contratados (internet, tel√©fono, seguridad, etc.)
Tipo de contrato y forma de pago
Cargos mensuales y totales
Y si el cliente ha abandonado o no la empresa (variable objetivo: Churn)
Entre otros...

# üîç 2da Preentrega - An√°lisis y Exploraci√≥n
## Exploraci√≥n y Transformaci√≥n
* Mostrar primeros 5 registros
* Mostrar √∫ltimos 5 registros
* Mostrar tipos de datos por columna
* Mostrar Cantidad de datos no nulos
* Mostrar Dimensiones del dataSet
* Transformaci√≥n de columna TotalCharges en n√∫merica
* Mostrar resumen estadistico de las columnas
* Sumar cantidad de nulos por columna
## An√°lisis
* C√°lculo del promedio de meses de permanencia
* C√°lculo del porcentaje de abandono general
* C√°lculo del estimado que gasto el cliente durante su tiempo de permanencia.
* Realizamos detecci√≥n de outliers
* C√°lculo de porcentaje de permanencia en relaci√≥n con el M√©todo de Pago
* C√°lculo de porcentaje de permanencia en relaci√≥n con el Tipo de Contrato
* C√°lculo de porcentaje de permanencia en relaci√≥n con el Tipo de Servicio de Internet
## Gr√°ficos
* Gasto mensual que poseen los clientes
* Antiguedad de clientes
* Relaci√≥n entre tipo de contrato y abandono
* Relaci√≥n entre g√©nero y abandono
* Relaci√≥n entre gasto mensual y abandono
* Relaci√≥n entre los tipos de servicios contratados y el abandono.

  # üß† 3ra Preentrega ‚Äì Clasificaci√≥n Supervisada

En esta etapa se desarrollaron modelos de **aprendizaje supervisado** con el objetivo de predecir si un cliente abandonar√° el servicio (variable objetivo: `Churn`). Para ello, se probaron distintos algoritmos de clasificaci√≥n, se aplicaron t√©cnicas de balanceo de clases y se evaluaron los modelos con diferentes m√©tricas.

El modelo que obtuvo mejores resultados fue **Random Forest**, optimizado con **GridSearchCV**, mostrando un buen desempe√±o general y equilibrio entre precisi√≥n y recall. Para mejorar la representaci√≥n de las clases, se aplic√≥ la t√©cnica de sobremuestreo **SMOTE**, ya que el dataset original estaba desbalanceado.

## Pasos realizados
* Preprocesamiento completo del dataset
  * Conversi√≥n de `TotalCharges` a num√©rico y manejo de valores nulos
  * Codificaci√≥n de variables categ√≥ricas
  * Escalado de los datos
* Separaci√≥n en variables predictoras (`X`) y objetivo (`y`)
* Balanceo de clases con **SMOTE**
* Divisi√≥n de datos en entrenamiento y testeo
* Entrenamiento y evaluaci√≥n de m√∫ltiples modelos de clasificaci√≥n:
  * Regresi√≥n Log√≠stica
  * √Årbol de Decisi√≥n
  * Random Forest (con hiperpar√°metros ajustados por GridSearch)
  * K-Nearest Neighbors
* Evaluaci√≥n con m√©tricas como:
  * Accuracy
  * Precision
  * Recall
  * F1-score
  * Curva ROC y AUC
* Visualizaci√≥n de la importancia de variables con Random Forest
* Comparaci√≥n de resultados entre modelos

## Conclusiones
El modelo final logr√≥ una **buena capacidad para detectar clientes en riesgo de abandonar** el servicio. La combinaci√≥n de Random Forest + GridSearch + SMOTE permiti√≥ mejorar notablemente los resultados. Adem√°s, se concluy√≥ que variables como el tipo de contrato, el gasto mensual y la antig√ºedad del cliente fueron claves para determinar el churn.

Este modelo puede ser utilizado por la empresa para anticiparse a la baja de clientes y aplicar estrategias de retenci√≥n personalizadas.


# üìä 4ta Preentrega ‚Äì An√°lisis No Supervisado (Clustering)

En esta etapa se aplicaron t√©cnicas de aprendizaje no supervisado con el objetivo de identificar agrupamientos naturales de clientes basados en sus caracter√≠sticas y comportamientos. A diferencia de las etapas anteriores, en esta fase no se utiliz√≥ una variable objetivo como ‚ÄúChurn‚Äù, sino que se busc√≥ descubrir patrones ocultos en los datos. Se consider√≥ inicialmente la posibilidad de aplicar DBSCAN, ya que puede detectar grupos de diferentes formas y tama√±os sin necesidad de predefinir el n√∫mero de clusters, pero sus resultados no fueron satisfactorios debido a la sensibilidad a los par√°metros y a que el dataset estaba muy estructurado. Por eso se opt√≥ por el algoritmo **K-Means**, que se adapta mejor a datos num√©ricos, escalados y con distribuci√≥n uniforme, como los del dataset trabajado. Para determinar la cantidad √≥ptima de clusters se utilizaron los m√©todos del Codo (Elbow) y el Score de Silhouette, y para facilitar la visualizaci√≥n de los grupos formados se aplic√≥ **PCA** (An√°lisis de Componentes Principales), reduciendo la dimensionalidad a dos componentes principales.

## Pasos realizados
* Preprocesamiento del dataset (eliminaci√≥n de columnas irrelevantes, codificaci√≥n de variables categ√≥ricas, escalado)
* Eliminaci√≥n de la variable `Churn` para respetar la l√≥gica de an√°lisis no supervisado
* Reducci√≥n de dimensionalidad con **PCA**
* Determinaci√≥n del n√∫mero √≥ptimo de clusters con:
  * M√©todo del Codo (Elbow Method)
  * Score de Silhouette
* Aplicaci√≥n de **K-Means** con el valor √≥ptimo de k
* Visualizaci√≥n final de los clusters en un gr√°fico 2D
* Conteo y an√°lisis b√°sico de la distribuci√≥n de clientes por cluster

## ¬øPara qu√© sirve este an√°lisis?
Este tipo de segmentaci√≥n permite a las empresas:
* Identificar perfiles de clientes con comportamientos similares
* Detectar grupos con mayor riesgo potencial de abandono (en futuras fases podr√≠an cruzarse los clusters con la variable `Churn`)
* Dise√±ar estrategias espec√≠ficas de fidelizaci√≥n para cada segmento

El an√°lisis no supervisado complementa la predicci√≥n de abandono al aportar una mirada m√°s estrat√©gica sobre el conjunto total de clientes, incluso sin saber si se ir√°n o no.

  
# üõ†Ô∏è Herramientas Utilizadas
* Python üêç
* Pandas üìö
* NumPy üî¢
* Matplotlib & Seaborn üìä
* Scikit-learn ü§ñ
* Google Colab ‚òÅÔ∏è
